<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Probabilidad y Estadística</title>
    <script src="https://github.com/KaTeX/KaTeX"></script>
</head>
<body>
    <h1>Estadística descriptiva</h1>
    <h3>-Conceptos básicos de estadística</h3>
    <ul>
        <li>Definición: La estadística se refiere a datos numéricos, tales como promedios, medianas, porcentajes e índices que caracterizan un objeto de estudio o de referencia.<br><br>
        La estadística descriptiva intenta definir un objeto de estudio y mostrar el conjunto de atributos que se consideran importantes a la hora de describir el estado de dicho objeto.</li><br>
        <li>Teoría de decisión: Es un enfoque que busca proporcionar un marco para la toma de decisiones en situaciones de incertidumbre. Esta teoría se basa en la idea de que las decisiones se toman en función de la información disponible y las posibles consecuencias de cada opción.</li><br>
        <li>Población: Una población estadística es, en esencia, un grupo de individuos o elementos que tienen algo en común. Ese ‘algo’ es lo que queremos estudiar.</li><br>
        <li>Muestra aleatoria: Una muestra aleatoria es un subconjunto de la población que se selecciona de manera aleatoria y que se utiliza para hacer inferencias sobre la población.</li><br>
        <li>Parámetros aleatorios: Se llama variable aleatoria aquella que toma diversos valores o conjuntos de valores con distintas probabilidades. Existen 2 características importantes de una variable aleatoria, sus valores y las probabilidades asociadas a esos valores.</li>
    </ul>
    <h3>-Descripción de datos</h3>
    <ul>
        <li>Datos agrupados y no agrupados: Cuando la muestra de la población o proceso que se desea analizar, es decir, se tiene menos de 20 elementos, entonces estos datos son analizados sin necesidad de formar clases con ellos, se le denomina tratamiento de datos no agrupados<br>
        En cambio, si la muestra consta de 30 o mas datos, es mejor agrupar los datos en clases y en base a estas determinar las características de la muestra, estos son los datos agrupados</li><br>
        <li>Frecuencias de clase: <br>
            Marca de clase (punto medio): punto que divide a la clase en dos partes iguales. Es el promedio entre los límites superior e inferior de la clase.
            <br><br>
            Intervalo de clase: para una distribución de frecuencias que tiene clases del mismo tamaño, el intervalo de clase se obtiene restando el límite inferior de una clase del límite inferior de la siguiente.</li><br>
        <li>Punto medio: Es el punto que divide a un segmento en dos partes iguales.</li><br>
        <li>Limites: Son los valores extremos que tiene el intervalo de clase, inferior y superior, entre los cuales van a estar los valores de los datos agrupados en ese intervalo de clase.</li>
    </ul>
    <h3>-Medidas de tendencia central</h3>
    <ul>
        <li>Media aritmetica: También conocida como promedio, se calcula sumando todos los valores y dividiendo entre la cantidad de valores. </li><br>
        <li>Media geometrica: Se utiliza para calcular el promedio de una serie de valores multiplicativos.</li><br>
        <li>Media ponderada: En este caso, se asignan pesos a cada valor antes de calcular la media.</li><br>
        <li>Mediana:Es el valor de la variable que divide a la distribución de frecuencias en dos partes iguales.</li><br>
        <li>Moda: Es el valor que cuenta con una mayor frecuencia en una distribución de datos.</li><br>
        <li>Medidas de dispersión: Las medidas de dispersión, también conocidas como medidas de variabilidad, son indicadores estadísticos utilizados para cuantificar la extensión o la variabilidad de un conjunto de datos.</li>
        <li>Varianza: La varianza mide cuánto se dispersan los valores individuales con respecto a la media aritmética.</li><br>
        <li>Desviación estándar: Es simplemente la raíz cuadrada de la varianza.</li><br>
        <li>Desviación media: Calcula la media de las diferencias absolutas entre cada valor y la media.</li><br>
        <li>Desviación mediana: Similar a la desviación media, pero utilizando la mediana en lugar de la media.</li><br>
        <li>Rango: Es la diferencia entre el valor máximo y el valor mínimo en el conjunto de datos.</li>
    </ul>
    <h3>-Parametros para datos agrupados</h3>
    <ol>
        <h4>Pasos para agrupar datos</h4>
        <li>Determinar el rango o recorrido de los datos.</li>
        <li>Establecer el número de clases en que se van a agrupar los datos</li>
        <li>Determinar la amplitud de clase para agrupar</li>
        <li>Formar clases y agrupar datos</li>
    </ol>
    <h3>-Distribución de frecuencias</h3>
    <h4>Distribución de frecuencia para datos no Agrupados: </h4>
    <p>Es aquella distribución que indica las frecuencias con que aparecen los datos estadísticos, desde el menor de ellos hasta el mayor de ese conjunto sin que se haya hecho ninguna modificación al tamaño de las unidades originales. </p>
    <h4>Distribución de frecuencia de clase o de datos Agrupados: </h4>
    <p>Es aquella distribución en la que la disposición tabular de los datos estadísticos se encuentran ordenados en clases y con la frecuencia de cada clase; es decir, los datos originales de varios valores adyacentes del conjunto se combinan para formar un intervalo de clase.</p>
    <h4>Componentes de una distribución de frecuencia de clase</h4>
    <ol>
        <li>Rango o amplitud total (recorrido)</li>
        <li>Claso o intervalo de clase</li>
        <li>Amplitud de clase, longitud o ancho de una clase</li>
        <li>Punto medio o marca de clase</li>
        <li>Frecuencia de clase</li>
        <li>Frecuencia relativa</li>
        <li>Frecuencias acumuladas</li>
        <li>Frecuencia acumulada relativa</li>
    </ol>
    <h3>-Técnicas de agrupación de datos</h3>
    <p>La agrupación de datos es un proceso importante en el análisis de datos, que implica combinar datos relacionados para obtener una visión general y descubrir patrones, tendencias y relaciones entre ellos.</p>
    <ul>
        <li>Agrupación por intervalos: La agrupación por intervalos implica dividir los datos en intervalos o rangos y agruparlos según los valores que caen dentro de cada intervalo. .</li>
        <li>Agrupación por categorías: La agrupación por categorías implica agrupar los datos según categorías o grupos predefinidos. Por ejemplo, se puede agrupar los datos de género en masculino y femenino.</li>
        <li>Agrupación por clustering: El análisis de clustering es una técnica de agrupación de datos que implica agrupar objetos o individuos en grupos (clústeres) según sus características o atributos.</li>
        <li>Agrupación por k-medias: La agrupación por k-medias es una técnica de agrupación de datos que implica dividir los datos en k grupos (clústeres) según la distancia entre los puntos de datos y la media de cada grupo.</li>
        <li>Agrupación por k-mediana: La agrupación por k-mediana es similar a la agrupación por k-medias, pero se utiliza la mediana en lugar de la media para determinar la agrupación.</li>
        <li>Agrupación por dendrograma: La agrupación por dendrograma es una técnica de agrupación de datos que implica construir un árbol jerárquico (dendrograma) que representa la relación entre los datos y agruparlos según la distancia entre ellos.</li>
        <li>Agrupación por hierarquía: La agrupación por hierarquía es una técnica de agrupación de datos que implica construir una jerarquía de agrupaciones según la distancia entre los datos y agruparlos según la jerarquía.</li>
        <li>Agrupación por agrupación jerárquica: La agrupación por agrupación jerárquica es una técnica de agrupación de datos que implica construir una jerarquía de agrupaciones y agrupar los datos según la jerarquía.</li>
        <li>Agrupación por agrupación no jerárquica: La agrupación por agrupación no jerárquica es una técnica de agrupación de datos que implica agrupar los datos según una función de agrupación no jerárquica, como la distancia entre los puntos de datos.</li>
        <li>Agrupación por agrupación dinámica: La agrupación por agrupación dinámica es una técnica de agrupación de datos que implica agrupar los datos según una función de agrupación dinámica, que cambia según los datos.</li>
    </ul>
    <h3>-Técnicas de muestreo</h3>
    <ul>
        <li>Muestreo probabilístico: Forman parte de este tipo de muestreo todos aquellos métodos para los que puede calcular la probabilidad de extracción de cualquiera de las muestras posibles.</li>
        <li>Muestreo estratificado: Consiste en la división previa de la población de estudio en grupos o clases que se suponen homogéneos con respecto a alguna característica de las que se van a estudiar.</li>
        <li>Muestreo sistemático: Se utiliza cuando el universo o población es de gran tamaño, o ha de extenderse en el tiempo. Primero hay que identificar las unidades y relacionarlas con el calendario (cuando proceda).</li>
        <li>Muestreo por estadios múltiples: Esta técnica es la única opción cuando no se dispone de lista completa de la población de referencia o bien cuando por medio de la técnica de muestreo simple o estratificado se obtiene una muestra con unidades distribuidas de tal forma que resultan de difícil acceso.</li>
        <li>Muestreo por conglomerado: Técnica similar al muestreo por estadios múltiples, se utiliza cuando la población se encuentra dividida, de manera natural, en grupos que se supone que contienen toda la variabilidad de la población</li>
        <li>Muestreo no probabilístico: Aquél para el que no puede calcularse la probabilidad de extracción de una determinada muestra. Se busca seleccionar a individuos que se juzga de antemano tienen un conocimiento profundo del tema bajo estudio, por lo tanto, se considera que la información aportada por esas personas es vital para la toma de decisiones. </li>
        <li>Muestreo por cuotas: Es la técnica más difundida sobre todo en estudios de mercado y sondeos de opinión. En primer lugar es necesario dividir la población de referencia en varios estratos definidos por algunas variables de distribución conocida (como el género o la edad).</li>
    
    </ul>
    <h3>-Histogramas</h3>
    <p>En estadística, un histograma es una representación gráfica de una variable en forma de barras, donde la superficie de cada barra es proporcional a la frecuencia de los valores representados. En el eje vertical se representan las frecuencias, y en el eje horizontal los valores de las variables, normalmente señalando las marcas de clase, es decir, la mitad del intervalo en el que están agrupados los datos.</p>
    <ol>
        <h4>Tipos de histograma</h4>
        <li>Diagramas de barras simples: Representa la frecuencia simple (absoluta o relativa) mediante la altura de la barra la cual es proporcional a la frecuencia simple de la categoría que representa.</li>
        <li>Diagramas de barras compuesta: Se usa para representar la información de una tabla de doble entrada o sea a partir de dos variables, las cuales se representan así; la altura de la barra representa la frecuencia simple de las modalidades o categorías de la variable y esta altura es proporcional a la frecuencia simple de cada modalidad.</li>
        <li>Diagramas de barras agrupadas: Se usa para representar la información de una tabla de doble entrada o sea a partir de dos variables, el cual es representado mediante un conjunto de barras como se clasifican respecto a las diferentes modalidades.</li>
        <li>Polígono de frecuencias: Es un gráfico de líneas que de las frecuencias absolutas de los valores de una distribución en el cual la altura del punto asociado a un valor de las variables es proporcional a la frecuencia de dicho valor.</li>
        <li>Ojiva porcentual: Es un gráfico acumulativo, el cual es muy útil cuando se quiere representar el rango porcentual de cada valor en una distribución de frecuencias.</li>
    </ol>
    <br>
    <br>

    <h1>Fundamentos de la teoría de probabilidad</h1>

    <h2>2.2 Teoría elemental de probabilidad</h2>
    <p> El Cálculo de Probabilidades se ocupa de estudiar ciertos experimentos que se denominan aleatorios, cuya característica fundamental es la incertidumbre del resultado, esto significa que es imposible predecir los resultados porque hay más de uno posible.
        <br>Son ejemplos de experimentos aleatorios: lanzar un dado cinco veces, los instantes de llegadas a un abarrote, etc. 
        <br>El término de probabilidad es de uso común, así el ente televisivo, el cual nos dirá que es poco probable un cambio brusco de temperatura ó un periódico informará que es muy probable que el Real Madrid gane en su campo a Las Palmas.
        <br><br>Este tipo de información es insuficiente cuando se necesita un conocimiento más profundo de un fenómeno aleatorio, Supongamos que una compañía de seguros va a extender una póliza por seguro de vida a un cliente.  </p>

    <h2>2.3 Probabilidad de Eventos: Definición de espacio muestral, definición de evento, simbología, unión, intersección, diagramas de Venn </h2>
    <p>Definición de Espacio muestral (E): es el conjunto de los diferentes resultados que pueden darse en un experimento aleatorio o cuando se realiza un experimento, que es cualquier proceso que produce un resultado o una observación, se van a obtener un conjunto de valores.
        <br><br>A este conjunto de valores que puede tomar una variable se le denomina espacio muestral. 
        <br><br>Por ejemplo: Si se tiene un dado cualquiera, el espacio muestral (EM) es EM={1,2,3,4,5,6}. 
        <br><br>Experimento {Lanzar un dado}, E={1,2,3,4,5,6} Experimento {Lanzar una moneda}, E={Cara, Cruz}</p>
    <h2>2.4 Probabilidad con Técnicas de Conteo: Axiomas, Teoremas </h2>
    <p>Los axiomas de probabilidad son las condiciones mínimas que deben verificarse para que una función definida sobre un conjunto de sucesos determine consistentemente sus probabilidades.
        <br><br>AXIOMA 1   Si A es un evento de S, entonces la probabilidad del evento A es:   0 ≤ P(A) ≤ 1 Como no podemos obtener menos de cero éxitos ni más de  n éxitos en  n experimentos, la  probabilidad de cualquier evento A, se representa mediante un valor que puede variar de 0 a 1. 
        <br><br>AXIOMA 2   Si dos eventos son mutuamente excluyentes, la probabilidad de obtener  A o  B es igual a la probabilidad de obtener A más la probabilidad de obtener B.   P(A ∪ B) = P(A) + P(B)  Excluirse mutuamente quiere decir que  A y  B no pueden ocurrir simultáneamente en el mismo experimento. Así, la probabilidad de obtener águila o sol  en la misma tirada de una moneda será   P(A ∪ B) = P(A) + P(B)   P(A ∪ B) = 1/2 + 1/2  = 1.  En general podemos decir que la suma de las probabilidades de todos los posibles eventos  mutuamente excluyentes es igual a 1:   P(A1) + P(A2) + P(A3) + ... + P(An) = 1  
        <br><br>AXIOMA 3   Si A es un evento cualquiera de un experimento aleatorio y A’ es el complemento de A, entonces:   P(A’) = 1 -  P(A)  Es decir, la probabilidad de que el evento A no ocurra, es igual a 1 menos la probabilidad de que ocurra.</p>
    <h2>2.5 Probabilidad condicional: Dependiente, Independiente </h2>
    <p>Eventos Independientes  
        <br>Dos o más eventos son independientes cuando la ocurrencia o no-ocurrencia de un evento no tiene efecto sobre la probabilidad de ocurrencia del otro evento (o eventos). Un caso típico de eventos independiente es el muestreo con reposición, es decir, una vez tomada la muestra se regresa de nuevo a la población donde se obtuvo.
        <br>Eventos dependientes
        <br>Dos o más eventos serán dependientes cuando la ocurrencia o no-ocurrencia de uno de ellos afecta la probabilidad de ocurrencia del otro (o otros). Cuando tenemos este caso, empleamos entonces, el concepto de probabilidad condicional para denominar la probabilidad del evento relacionado. La expresión P (A|B) indica la probabilidad de ocurrencia del evento A sí el evento B ya ocurrió.   </p>
    
    <h2>2.6 Ley multiplicativa </h2>
    <p>Al multiplicar la formula P(B/A) =P( A Ç B)/ P(A) por P( A); obtenemos la siguiente regla multiplicativa, esta es importante por que nos permite calcular la probabilidad de que ocurran dos eventos. 
        <br>Teorema: si un experimento pueden ocurrir los eventos A y B, entonces P( A Ç B)= P( A) P(B/A). así la probabilidad de que ocurran A y B es igual a la probabilidad de que ocurra A multiplicada por la probabilidad de que ocurra B, dado que ocurre A.  </p>
    
    <h2>2.7 Eventos independientes: Regla de Bayes </h2>
    <p>Sea d un espacio muestral que está formado por los eventos A1, A2, A3,.....,An mutuamente excluyentes, luego, d = A1ÈA2ÈA3È.....ÈAn
        <br>Luego si ocurre un evento B definido en d, observamos que; <br>B = dÇB = (A1ÈA2ÈA3È.....ÈAn)ÇB = (A1ÇB)È(A2ÇB)È(A3ÇB)È.....È(AnÇB)  
        <br>Donde cada uno de los eventos AiÇB son eventos mutuamente excluyentes, por lo que  <br>p(B) = p(A1ÇB) + p(A2ÇB) + p(A3ÇB) +......+ p(AnÇB)  
        <br>y como la p(AiÇB) = p(Ai)p(B½Ai) , o sea que la probabilidad de que ocurra el evento Ai y el evento B es igual al teorema de la multiplicación para probabilidad condicional, luego;  <br>p(B) = p(A1)p(B½A1) + p(A2)p(B½A2) + p(A3)p(B½A3) + p(An)p(B½An)  
    <br>
    <br>


    <h1>Variables Aleatorias.
    </h1>
    
    
    <p>Una variable aleatoria es una función que asigna un valor numérico, al resultado de un experimento aleatorio. Recordemos que el resultado de un experimento aleatorio depende del azar. </p>
    <a href='https://www.canva.com/design/DAGJ0BvbM5Q/6OId_L51-NqKRWfjkXVcNQ/view?utm_content=DAGJ0BvbM5Q&utm_campaign=designshare&utm_medium=link&utm_source=recording_view' >Video de variables aleatorias discretas</a>

    <h2>3.1 Variables aleatorias discretas</h2>
    <p>Una variable aleatoria discreta es aquella que solo puede tomar un conjunto finito o contable de valores. Por ejemplo, el número de caras que salen al lanzar una moneda, el número de defectos en una producción industrial o el número de clientes que llegan a una tienda en una hora.</p>

    <h3>3.1.1 Distribución de probabilidad en forma general</h3>
    <p>La distribución de probabilidad de una variable aleatoria discreta X se define como la función que asigna a cada valor posible de X su probabilidad correspondiente.</p>

    <h3>3.1.2 Valor esperado</h3>
    <p>El valor esperado, también conocido como media poblacional, de una variable aleatoria discreta X se define como la suma de los productos de cada valor posible de X por su probabilidad correspondiente. </p>

    <h3>3.1.3 Varianza, desviación estándar</h3>
    <p>La varianza de una variable aleatoria discreta X mide la dispersión de sus valores alrededor del valor esperado. Se define como la suma de los cuadrados de las desviaciones de cada valor posible de X respecto al valor esperado, multiplicadas por sus probabilidades correspondientes.</p>

    <h3>3.1.4 Función acumulada</h3>
    <p>La función acumulada de una variable aleatoria discreta X representa la probabilidad de que X tome un valor menor o igual a un determinado valor x</p>
    <a href='https://www.canva.com/design/DAGJ0Q9gKd0/capWSpHxIT2IamfelvoU_A/view?utm_content=DAGJ0Q9gKd0&utm_campaign=designshare&utm_medium=link&utm_source=recording_view' >Video de variables aleatorias continuas</a>

    <h2>3.2 Variables aleatorias continuas</h2>
    <p>Una variable aleatoria continua es aquella que puede tomar cualquier valor (al menos teóricamente) entre dos valores fijados. Los valores de la variable (al menos teóricamente) no se repiten.</p>

    <h3>3.2.1 Distribución de probabilidad en forma general</h3>
    <p>Una variable aleatoria continua es aquella que puede tomar un conjunto infinito y no numerable de valores dentro de un intervalo determinado. Por ejemplo, la altura de una persona, el tiempo de espera en una fila o la temperatura ambiente.</p>

    <h3>3.2.2 Valor esperado</h3>
    <p>El valor esperado de una variable aleatoria continua X se define como el límite de la suma de los productos de cada valor posible de X por su probabilidad correspondiente, a medida que el ancho de los intervalos considerados tiende a cero. </p>

    <h3>3.2.3 Varianza, desviación estándar</h3>
    <p>La varianza y la desviación estándar de una variable aleatoria continua se calculan de forma similar al caso de las variables discretas, pero utilizando integrales en lugar de sumas.</p>

    <h3>3.2.4 Función acumulada</h3>
    <p>La función acumulada de una variable aleatoria continua X (F(x)) representa la probabilidad de que X tome un valor menor o igual a un determinado valor x.</p>

    <h3>3.2.5 Cálculos de probabilidad</h3>
    
    <p>Una de las principales diferencias entre variables discretas y continuas radica en el cálculo de probabilidades. En el caso de variables continuas, como la probabilidad de que X tome un valor exacto es cero, se suelen calcular las probabilidades de que X se encuentre dentro de un intervalo determinado.</p>

    <a href="Testing.html">Haz clic aquí para ir a los ejercicios del tema 3</a>

    

    <h3>4.1 Función de probabilidad.</h3>
    <p>En el ámbito de la teoría de la probabilidad, la función de probabilidad juega un papel crucial. Esta función se define como una representación matemática que asigna a cada posible resultado de un experimento aleatorio la probabilidad de que dicho resultado ocurra. La suma de las probabilidades asignadas a todos los resultados posibles debe ser igual a 1.</p>
    
    <h3>4.2 Distribución binomial.</h3>
    <p>La distribución binomial se emplea para modelar situaciones donde se realizan "n" experimentos aleatorios independientes, cada uno con la misma probabilidad de éxito "p". Esta distribución describe la probabilidad de obtener "x" éxitos en esos "n" experimentos. Se utiliza comúnmente en escenarios como lanzar una moneda, realizar pruebas de diagnóstico o analizar resultados electorales.</p>
    <img src="fBinomial.png" alt="Formula Binomial">
    <p>Su formula de la media es: <img src="BinomM.png" alt="Poisson"></p>
    <p>Su formula de la varianza es: <img src="BinomV.png" alt="Poisson"></p>

    <h3>4.3 Distribución hipergeométrica.</h3>
    <p>La distribución hipergeométrica se aplica en situaciones donde se extrae una muestra sin reposición de un conjunto finito que contiene elementos de dos categorías (éxito y fracaso). Esta distribución calcula la probabilidad de obtener "x" resultados de una categoría específica ("éxito") en esa muestra de tamaño "n". Se utiliza en escenarios como la selección de un comité o la auditoría de lotes de productos.</p>
    <img src="DistribucionHipergeometrica.png" alt="Distribución Hipergeométrica">
    <p>Su formula de la media es: <img src="HiperM.png" alt="Poisson"></p>
    <p>Su formula de la varianza es: <img src="HiperV.png" alt="Poisson"></p>

    <h3>4.4 Distribución de Poisson.</h3>
    <p>La distribución de Poisson se utiliza para modelar la cantidad de eventos que ocurren en un intervalo de tiempo o espacio determinado, suponiendo que la tasa de ocurrencia es constante y los eventos son independientes entre sí. Esta distribución es útil en situaciones como el número de llamadas telefónicas recibidas en un centro de atención al cliente o la cantidad de defectos en una hoja de metal.</p>
    <img src="DistribucionPoisson.png" alt="Distribución de Poisson">
    <p>Su formula de la media es: <img src="P.png" alt="Poisson"></p>
    <p>Su formula de la varianza es: <img src="P.png" alt="Poisson"></p>

    <h3>4.5 Distribución normal.</h3>
    <p>La distribución normal, también conocida como distribución de Gauss, es una de las distribuciones de probabilidad más importantes en estadística. Se caracteriza por su forma de campana simétrica, donde la mayoría de los datos se agrupan alrededor de la media y la probabilidad de valores extremos disminuye a medida que se alejan de ella. Esta distribución se aplica en una amplia gama de escenarios, desde mediciones físicas hasta análisis financieros.</p>
    <img src="DistribucionNormal.png" alt="Distribucion normal">
    <p>Su formula de la media es: <img src="NorM.png" alt="Poisson"></p>
    <p>Su formula de la varianza es: <img src="NorV.png" alt="Poisson"></p>

    <h3>4.6 Distribución T-student.</h3>
    <p>La distribución T-student se utiliza en lugar de la distribución normal cuando el tamaño de la muestra es pequeño y la población presenta una varianza desconocida. Esta distribución es más robusta que la normal ante la presencia de valores atípicos (outliers) y se emplea en pruebas de hipótesis e intervalos de confianza.</p>
   
    <h3>4.7 Distribución Chi cuadrada.</h3>
    <p>La distribución Chi cuadrada se utiliza para evaluar la independencia entre dos variables categóricas o para analizar la varianza de una muestra en comparación con la varianza de una población conocida. Esta distribución se aplica en pruebas de hipótesis, como la prueba de Chi cuadrado de independencia o la prueba de Chi cuadrado de bondad de ajuste.</p>
    
    <h3>4.8 Distribución F.</h3>
    <p>La distribución F se utiliza para comparar la varianza de dos muestras independientes. Esta distribución es útil en pruebas de hipótesis, como la prueba F de Snedecor, para determinar si existe una diferencia significativa en la varianza entre dos grupos.</p>
    
    <a href='https://drive.google.com/file/d/146wPTgbHW6mluoIeUBNDyKWhHiCH_Mt3/view?usp=drive_link' >Ejercicio 7 explicación</a>
    <br><br><a href="ejercicios.html">Haz clic aquí para ir a los ejercicios del tema 4</a>

    <h1>Regresión lineal</h1>
    <h2>5.1 Regresión y correlación</h2>
    <h3>5.1.1 Diagrama de dispersión</h3>
    <p>El diagrama de dispersión es una representación gráfica de la relación entre dos variables. Se utiliza para visualizar la correlación entre las variables y para identificar patrones en los datos.</p>
    <h3>5.1.2 Regresión lineal simple</h3>
    <p>La regresión lineal simple es un modelo estadístico que describe la relación lineal entre dos variables. Se utiliza para predecir el valor de una variable (variable dependiente) en función del valor de la otra variable (variable independiente).</p>
    <h3>5.1.3 Correlación</h3>
    <p>La correlación es una medida de la asociación entre dos variables. Indica si las variables se mueven en la misma dirección, en direcciones opuestas o si no están relacionadas.</p>
    <h3>5.1.4 Determinación y análisis de los coeficientes de correlación y de determinación</h3>
    <p>El coeficiente de correlación (r) es una medida de la fuerza de la correlación entre dos variables. El coeficiente de determinación (R²) es una medida de la proporción de la varianza de la variable dependiente que se puede explicar por la variable independiente.</p>
    <h3>5.1.5 Distribución normal bidimensional</h3>
    <p>La distribución normal bidimensional es una distribución de probabilidad conjunta de dos variables continuas. Se utiliza para modelar la relación entre dos variables que se distribuyen normalmente.</p>
    <h3>5.1.6 Intervalos de confianza y pruebas para el coeficiente de correlación</h3>
    <p>Los intervalos de confianza y las pruebas de hipótesis se utilizan para inferir sobre la población a partir de una muestra. En el caso de la correlación, se pueden utilizar para estimar el valor real de la correlación en la población y para determinar si la correlación es estadísticamente significativa.</p>
    <h3>5.1.7 Errores de medición</h3>

</body>
</html>